{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alexandre Hirsch, Antonin Wattel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import json\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.test.utils import datapath\n",
    "#import nltk\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "#from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 217801\n",
      "Number of edges: 1718164\n"
     ]
    }
   ],
   "source": [
    "#5.9s\n",
    "\n",
    "# read training data\n",
    "df_train = pd.read_csv('train.csv', dtype={'author': np.int64, 'hindex': np.float32})\n",
    "n_train = df_train.shape[0]\n",
    "\n",
    "# read test data\n",
    "df_test = pd.read_csv('test.csv', dtype={'author': np.int64})\n",
    "n_test = df_test.shape[0]\n",
    "\n",
    "# load the graph    \n",
    "G = nx.read_edgelist('coauthorship.edgelist', delimiter=' ', nodetype=int)\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges() \n",
    "print('Number of nodes:', n_nodes)\n",
    "print('Number of edges:', n_edges)\n",
    "\n",
    "#core_number = nx.core_number(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from abstracts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model loaded\n"
     ]
    }
   ],
   "source": [
    "#1m40s\n",
    "\n",
    "#try with different pre-trained word-embedding models\n",
    "wv = api.load('word2vec-google-news-300')\n",
    "#wv = api.load('glove-wiki-gigaword-300')\n",
    "print(\"Word2Vec model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train our own word2vec model on the abstracts (-> this does not perform so well)\n",
    "#sentences2 = []\n",
    "#sentences2 = [[word for word in nltk.word_tokenize(s) if word.isalnum()] for s in sentences]\n",
    "#model = Word2Vec(sentences2, sg = 1)\n",
    "#print(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstracts stored\n"
     ]
    }
   ],
   "source": [
    "#2m 40s\n",
    "\n",
    "def store_abstracts():\n",
    "    paper_IDs = dict()\n",
    "    #with open('abstracts.txt') as f:\n",
    "    with open('abstracts.txt', encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            paper_ID, abstract = l.split(\"----\",1)\n",
    "            #sent = [None]*d[\"IndexLength\"]\n",
    "            #for word, v in d[\"InvertedIndex\"].items():\n",
    "                #for i in v:\n",
    "                    #sent[i] = word\n",
    "            #sentences += nltk.sent_tokenize(' '.join(list(filter(None, sent))))\n",
    "            paper_IDs[int(paper_ID)] = json.loads(abstract)[\"InvertedIndex\"].keys() - STOPWORDS\n",
    "    return paper_IDs #, sentences\n",
    "\n",
    "paper_IDs = store_abstracts()\n",
    "print('abstracts stored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors stored\n"
     ]
    }
   ],
   "source": [
    "#12 s\n",
    "\n",
    "def store_authors():\n",
    "    author_IDs = dict()\n",
    "    with open('author_papers.txt') as f:\n",
    "        for l in f:\n",
    "            author_ID, papers = l.split(':')\n",
    "            author_IDs[int(author_ID)] = map(int,papers.split('-'))\n",
    "    return author_IDs\n",
    "    \n",
    "author_IDs = store_authors()\n",
    "print('authors stored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paper_value(paper_ID):\n",
    "    vec = np.zeros(wv.vector_size)\n",
    "    try:\n",
    "        words_used = set()\n",
    "        for token in paper_IDs[paper_ID]:\n",
    "            words = re.sub(r'[-/]', ' ', re.sub(r'[.…,:?!;\\'‘’\"“”()*–]|[0-9]+-|[0-9]|\\'s', '', token))\n",
    "            for w in words.split():\n",
    "                if w not in STOPWORDS and w not in words_used:\n",
    "                    words_used.add(w)\n",
    "                    try:\n",
    "                        vec += wv[w]\n",
    "                    except:\n",
    "                        continue\n",
    "    except:\n",
    "        pass\n",
    "    return vec\n",
    "\n",
    "def get_author_value(author_ID):\n",
    "    vec = np.zeros(wv.vector_size)\n",
    "    for paper_ID in author_IDs[author_ID]:\n",
    "        vec += get_paper_value(paper_ID)\n",
    "    return vec\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "X_train = np.zeros((n_train, wv.vector_size))\n",
    "y_train = np.zeros(n_train)\n",
    "\n",
    "\n",
    "# X_train_1 = np.zeros((n_train, df_train_1.shape[0]))\n",
    "# y_train_1 = np.zeros(n_train)\n",
    "\n",
    "# X_validation = np.zeros((n_train, df_test_1.shape[0]))\n",
    "# y_validation = np.zeros(n_train)\n",
    "\n",
    "\n",
    "for i,row in df_train.iterrows():\n",
    "    author = row['author']\n",
    "    X_train[i,:] = get_author_value(author)\n",
    "    y_train[i] = row['hindex']\n",
    "\n",
    "print('training data loaded')\n",
    "\n",
    "#this is useless for the moment----------\n",
    "# X_train_1 = X_train[:len(df_train)//5]\n",
    "# y_train_1 = y_train[:len(df_train)//5]\n",
    "\n",
    "# X_validation = X_train[len(df_train)//5:]\n",
    "# y_validation = y_train[len(df_train)//5:]\n",
    "#-------------------------------------------\n",
    "\n",
    "\n",
    "X_test = np.zeros((n_test, wv.vector_size))\n",
    "for i,row in df_test.iterrows():\n",
    "    author = row['author']\n",
    "    X_test[i,:] = get_author_value(author)\n",
    "print('testing data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(X_train_1.shape)\n",
    "# print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save feature vectors from the abstracts\n",
    "np.save('X_train_abstract.npy', X_train)\n",
    "np.save('X_test_abstract.npy', X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 217801\n",
      "Number of edges: 1718164\n"
     ]
    }
   ],
   "source": [
    "#10s\n",
    "\n",
    "# load the graph    \n",
    "G = nx.read_edgelist('coauthorship.edgelist', delimiter=' ', nodetype=int)\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges() \n",
    "print('Number of nodes:', n_nodes)\n",
    "print('Number of edges:', n_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features (no learning) -> centrality based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_number\n",
      "pagerank\n",
      "triangles\n",
      "deg_centrality\n"
     ]
    }
   ],
   "source": [
    "#careful: this takes time to run !!!! ()\n",
    "\n",
    "#https://arxiv.org/ftp/arxiv/papers/1911/1911.08795.pdf \n",
    "#https://www.geeksforgeeks.org/network-centrality-measures-in-a-graph-using-networkx-python/\n",
    "\n",
    "\n",
    "#let's just hope there is enough space in memory for all this\n",
    "\n",
    "core_number = nx.core_number(G)\n",
    "print('core_number')\n",
    "page_rank = nx.pagerank(G, alpha=0.9) #not so sure about the alpha\n",
    "print('pagerank')\n",
    "nb_triangles = nx.triangles(G)\n",
    "print('triangles')\n",
    "deg_centrality = nx.degree_centrality(G) \n",
    "print('deg_centrality')\n",
    "# close_centrality = nx.closeness_centrality(G)#veerrry long >40 m\n",
    "# print('closeness_centrality')\n",
    "# bet_centrality = nx.betweenness_centrality(G, normalized = True, endpoints = False)\n",
    "# print('bet_centrality')\n",
    "# eig_centrality = nx.eigenvector_centrality(G)\n",
    "# print('eigenvector_centrality')\n",
    "# katz_centrality = nx.katz_centrality(G)\n",
    "# print('katz_centrality')\n",
    "# current_flow_closeness_centrality = nx.current_flow_closeness_centrality(G)\n",
    "# print('current_flow')\n",
    "# current_flow_betweenness_centrality = nx.current_flow_betweenness_centrality(G)\n",
    "# print('current_flow_betweenness_centrality')\n",
    "# load_centrality = nx.load_centrality(G)\n",
    "# print('load_centrality')\n",
    "# harmonic_centrality = nx.harmonic_centrality(G)\n",
    "# print('harmonic')\n",
    "# percolation_centrality = nx.percolation_centrality(G)\n",
    "# print('percolation')\n",
    "# second_order_centrality = nx.second_order_centrality(G)\n",
    "# print('second oreder')\n",
    "# trophic_levels = nx.trophic_levels(G)\n",
    "# print('trophic levels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training features\n",
      "loaded testing features\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((n_train, 17))\n",
    "\n",
    "for i,row in df_train.iterrows():\n",
    "    author = row['author']\n",
    "    X_train[i, 0] = G.degree(author)\n",
    "    X_train[i, 1] = core_number[author]\n",
    "    X_train[i, 2] = page_rank[author]\n",
    "    X_train[i, 3] = nb_triangles[author]\n",
    "    X_train[i, 4] = deg_centrality[author]\n",
    "    # X_train[i, 5] = close_centrality[author]\n",
    "    # X_train[i, 6] = bet_centrality[author]\n",
    "    # X_train[i, 7] = eig_centrality[author]\n",
    "    # X_train[i, 8] = katz_centrality[author]\n",
    "    # X_train[i, 9] = current_flow_closeness_centrality[author]\n",
    "    # X_train[i, 10] = current_flow_betweenness_centrality[author]\n",
    "    # X_train[i, 11] = load_centrality[author]\n",
    "    # X_train[i, 12] = harmonic_centrality[author]\n",
    "    # X_train[i, 13] = percolation_centrality[author]\n",
    "    # X_train[i, 14] = second_order_centrality[author]\n",
    "    # X_train[i, 15] = trophic_levels[author]\n",
    "\n",
    "    #TO DO: largest clique number (he feature of a node is defined as the largest k of a k-clique that contains that node.)\n",
    "print('loaded training features')\n",
    "\n",
    "#-----------------------------\n",
    "\n",
    "X_test = np.zeros((n_test, 17))\n",
    "\n",
    "for i,row in df_test.iterrows():\n",
    "    author = row['author']\n",
    "    X_test[i, 0] = G.degree(author)\n",
    "    X_test[i, 1] = core_number[author]\n",
    "    X_test[i, 2] = page_rank[author]\n",
    "    X_test[i, 3] = nb_triangles[author]\n",
    "    X_test[i, 4] = deg_centrality[author]\n",
    "    # X_test[i, 5] = close_centrality[author]\n",
    "    # X_test[i, 6] = bet_centrality[author]\n",
    "    # X_test[i, 7] = eig_centrality[author]\n",
    "    # X_test[i, 8] = katz_centrality[author]\n",
    "    # X_test[i, 9] = current_flow_closeness_centrality[author]\n",
    "    # X_test[i, 10] = current_flow_betweenness_centrality[author]\n",
    "    # X_test[i, 11] = load_centrality[author]\n",
    "    # X_test[i, 12] = harmonic_centrality[author]\n",
    "    # X_test[i, 13] = percolation_centrality[author]\n",
    "    # X_test[i, 14] = second_order_centrality[author]\n",
    "    # X_test[i, 15] = trophic_levels[author]\n",
    "\n",
    "print('loaded testing features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_graph.npy', X_train)\n",
    "np.save('X_test_graph.npy', X_test)\n",
    "# np.save('X_train_1_graph.npy', X_train)\n",
    "# np.save('X_validation_graph.npy', X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use different graph methods to extract node embeddings from the graph\n",
    "(for the moment, we only use methods... )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THERE IS STILL WORK TO DO HERE !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "#convert IDs to numeric indices in order to use karate library\n",
    "\n",
    "#G_ = G.copy()\n",
    "#original_indices = [node for node in G.nodes()]\n",
    "#print(\"original = \", original_indices[0:10])\n",
    "#G = nx.convert_node_labels_to_integers(G, first_label=0, ordering='default')\n",
    "\n",
    "#to do: make sure we get bak to the same\n",
    "\n",
    "mapping_to_indices = { node : i for node, i in zip([node for node in G.nodes()], [i for i in range(n_nodes)]) }\n",
    "inverse_mapping = dict(zip(mapping_to_indices.values(),mapping_to_indices.keys()))\n",
    "G = nx.relabel_nodes(G, mapping_to_indices)\n",
    "\n",
    "node_indices = [node for node in G.nodes()]\n",
    "print(\"node = \", node_indices[0:10])\n",
    "\n",
    "\n",
    "\n",
    "#problem !!! we need to use an ordered dict here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a few hours to run...\n",
    "from karateclub.node_embedding.neighbourhood import Node2Vec \n",
    "\n",
    "model1 = Node2Vec()\n",
    "model1.fit(G)\n",
    "print('fitted Node2Vec')\n",
    "\n",
    "embedding1 = model1.get_embedding()\n",
    "np.save('Node2Vec_embedding.npy', embedding1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The node indexing is wrong.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15300/3862853937.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBoostNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fitted Node2Vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\karateclub\\node_embedding\\neighbourhood\\boostne.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \"\"\"\n\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_residuals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_target_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_base_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\karateclub\\estimator.py\u001b[0m in \u001b[0;36m_check_graph\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;34m\"\"\"Check the Karate Club assumptions about the graph.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\karateclub\\estimator.py\u001b[0m in \u001b[0;36m_check_indexing\u001b[1;34m(graph)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mnode_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mnumeric_indices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"The node indexing is wrong.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: The node indexing is wrong."
     ]
    }
   ],
   "source": [
    "#about 20 m\n",
    "from karateclub.node_embedding.neighbourhood import BoostNE\n",
    "\n",
    "model2 = BoostNE()\n",
    "model2.fit(G)\n",
    "print('fitted Node2Vec')\n",
    "\n",
    "embedding2 = model2.get_embedding()\n",
    "np.save('BoostNE_embedding.npy', embedding2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted Node2Vec\n"
     ]
    }
   ],
   "source": [
    "from karateclub.node_embedding.neighbourhood import NetMF\n",
    "\n",
    "model3 = NetMF()\n",
    "model3.fit(G)\n",
    "print('fitted Node2Vec')\n",
    "\n",
    "embedding3 = model3.get_embedding()\n",
    "np.save('NetMF_embedding.npy', embedding3  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1422: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted Node2Vec\n"
     ]
    }
   ],
   "source": [
    "from karateclub.node_embedding.neighbourhood import DeepWalk\n",
    "\n",
    "model = BoostNE()\n",
    "model.fit(G)\n",
    "print('fitted Node2Vec')\n",
    "\n",
    "embedding2 = model.get_embedding()\n",
    "np.save('DeepWalk_embedding.npy', embedding2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted Node2Vec\n"
     ]
    }
   ],
   "source": [
    "#12 s\n",
    "\n",
    "from karateclub.node_embedding.neighbourhood import RandNE\n",
    "\n",
    "model = RandNE()\n",
    "model.fit(G)\n",
    "print('fitted Node2Vec')\n",
    "\n",
    "embedding2 = model.get_embedding()\n",
    "np.save('RandNE_embedding.npy', embedding2  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.44 GiB for an array with shape (999001139,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15300/474257614.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGraRep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fitted Node2Vec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\karateclub\\node_embedding\\neighbourhood\\grarep.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, graph)\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_single_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morder\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mtarget_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_target_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_single_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\karateclub\\node_embedding\\neighbourhood\\grarep.py\u001b[0m in \u001b[0;36m_create_target_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;33m*\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtarget_matrix\u001b[0m\u001b[1;33m**\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSciPy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mPMI\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \"\"\"\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A_tilde\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A_tilde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A_tilde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A_tilde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A_tilde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \"\"\"\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# other * self\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\test_karate\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matmat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         fn(M, N, np.asarray(self.indptr, dtype=idx_dtype),\n\u001b[1;32m--> 523\u001b[1;33m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m            \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.44 GiB for an array with shape (999001139,) and data type int64"
     ]
    }
   ],
   "source": [
    "from karateclub.node_embedding.neighbourhood import GraRep\n",
    "\n",
    "model = GraRep()\n",
    "model.fit(G)\n",
    "print('fitted Node2Vec')\n",
    "\n",
    "embedding2 = model.get_embedding()\n",
    "np.save('GraRep.npy', embedding2  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now load training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not goood yet...\n",
    "\n",
    "#to do: relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_indices = np.load('original_indices.npy')\n",
    "#to d0: make this parralel\n",
    "\n",
    "# def load_data(embedding):\n",
    "#     X_train = np.zeros((n_train, embedding.shape[1]))\n",
    "#     #y_train = np.zeros(n_train)     \n",
    "    \n",
    "#     for i,row in df_train.iterrows():\n",
    "#         author = row['author']\n",
    "\n",
    "#         j = int(np.where(original_indices == author)[0]) #I guess this is really not efficient\n",
    "#         X_train[i,:] = embedding[j]#not index i #we need to access node with author_id \n",
    "\n",
    "#         #y_train[i] = row['hindex'] #We loaded this before\n",
    "\n",
    "#     print('training data loaded')\n",
    "\n",
    "#     X_train_1 = X_train[:len(df_train)//5]\n",
    "#     X_validation = X_train[len(df_train)//5:]\n",
    "\n",
    "\n",
    "#     X_test = np.zeros((n_test, wv.vector_size))\n",
    "#     for i,row in df_test.iterrows():\n",
    "#         author = row['author']\n",
    "#         j = np.where(np.array(original_indices) == author)[0]\n",
    "#         X_test[i,:] = embedding[j]# not the right order ?\n",
    "#     print('testing data loaded')\n",
    "\n",
    "#     return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #choose an embedding\n",
    "# embedding = np.load('Deepwalk_embedding_2.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test = load_data(embedding)\n",
    "# np.save('X_train_'+str(embedding)+'.npy', X_train)\n",
    "# np.save('X_test_'+str(embedding)+'.npy', X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relabelling test\n",
    "G = nx.relabel_nodes(G, inverse_mapping)\n",
    "#we have ids again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174241, 128)\n",
      "training data loaded\n",
      "testing data loaded\n"
     ]
    }
   ],
   "source": [
    "#6 s\n",
    "\n",
    "embedding = np.load('RandNE_embedding.npy')\n",
    "\n",
    "X_train = np.zeros((n_train, len(embedding[0])))\n",
    "y_train = np.zeros(n_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "for i,row in df_train.iterrows():\n",
    "    #print a counter\n",
    "    # if (i %100) == 0 :\n",
    "    #     print(i)\n",
    "    author = row['author']\n",
    "    #print(author)\n",
    "    #j = int(np.where(original_indices == author)[0]) #I guess this is really not efficient\n",
    "    j = mapping_to_indices[author]#not so sure\n",
    "    X_train[i,:] = embedding[j]#not index i #we need to access node with author_id \n",
    "    #y_train[i] = row['hindex']\n",
    "\n",
    "print('training data loaded')\n",
    "\n",
    "X_test = np.zeros((n_test, len(embedding[0])))\n",
    "for i,row in df_test.iterrows():\n",
    "    author = row['author']\n",
    "    #j = np.where(np.array(original_indices) == author)[0]\n",
    "    j = mapping_to_indices[author]#not so sure\n",
    "    #to do: write an exceptio\n",
    "    X_test[i,:] = embedding[j]# not the right order ?\n",
    "print('testing data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = np.load('meta_embedding.npy')\n",
    "\n",
    "# X_train = np.zeros((n_train, len(embedding[0])))\n",
    "# y_train = np.zeros(n_train)\n",
    "# print(X_train.shape)\n",
    "\n",
    "\n",
    "# for i,row in df_train.iterrows():\n",
    "#     #print a counter\n",
    "#     # if (i %100) == 0 :\n",
    "#     #     print(i)\n",
    "#     author = row['author']\n",
    "#     #print(author)\n",
    "#     j = int(np.where(original_indices == author)[0]) #I guess this is really not efficient\n",
    "#     X_train[i,:] = embedding[j]#not index i #we need to access node with author_id \n",
    "#     #y_train[i] = row['hindex']\n",
    "\n",
    "# print('training data loaded')\n",
    "\n",
    "# X_test = np.zeros((n_test, len(embedding[0])))\n",
    "# for i,row in df_test.iterrows():\n",
    "#     author = row['author']\n",
    "#     j = np.where(np.array(original_indices) == author)[0]\n",
    "#     #to do: write an exceptio\n",
    "#     X_test[i,:] = embedding[j]# not the right order ?\n",
    "# print('testing data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train_RandNE.npy', X_train)\n",
    "np.save('X_test_RandNE.npy', X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Now that we have features, we can assemble them and perform regression to get our prediction model.<br/>\n",
    "here, we load pre-computed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single cell for y_train (to run if not loaded yet)\n",
    "y_train = np.zeros(n_train)\n",
    "for i,row in df_train.iterrows():\n",
    "    y_train[i] = row['hindex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO: CHANGE THIS -> automatize this in order to stack any features easily\n",
    "\n",
    "a1 = np.load('X_train_abstract.npy')\n",
    "a2 = np.load('X_train_graph.npy')\n",
    "a3 = np.load('X_train_RandNE.npy')\n",
    "\n",
    "b1 = np.load('X_test_abstract.npy')\n",
    "b2 = np.load('X_test_graph.npy')\n",
    "b3 = np.load('X_test_RandNE.npy')\n",
    "\n",
    "\n",
    "#might meed normalization... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174241, 445)\n",
      "(43560, 445)\n"
     ]
    }
   ],
   "source": [
    "#stack features from the abstract and the graph\n",
    "\n",
    "X_train = np.concatenate((a1, a2, a3), axis=1)\n",
    "print(X_train.shape)\n",
    "X_test = np.concatenate((b1, b2, b3), axis=1)\n",
    "print(X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "#problem here ! -> the split must be randomized !\n",
    "\n",
    "s = np.arange(X_train.shape[0])\n",
    "np.random.shuffle(s)\n",
    "X_train  = X_train[s]\n",
    "y_train = y_train[s]\n",
    "\n",
    "# X_test = X_test[s]\n",
    "# y_test = y_test[s]\n",
    "\n",
    "\n",
    "X_train_1 = X_train[len(df_train)//5:]\n",
    "y_train_1 = y_train[len(df_train)//5:]\n",
    "\n",
    "X_validation= X_train[:len(df_train)//5]\n",
    "y_validation = y_train[:len(df_train)//5]\n",
    "\n",
    "\n",
    "#is this of any use ?\n",
    "# #X_test = np.zeros((n_test, wv.vector_size))\n",
    "# X_test = np.zeros((n_test, 1))\n",
    "# for i,row in df_test.iterrows():\n",
    "#     author = row['author']\n",
    "#     X_test[i,:] = get_author_value(author)\n",
    "# print('testing data loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.  4. 50. ...  2.  3.  1.]\n",
      "[ 7.  4. 50. ... 29.  6. 43.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- train:\n",
      "(174241, 445)\n",
      "(174241,)\n",
      "----- train_1\n",
      "(139393, 445)\n",
      "(139393,)\n",
      "----- validation\n",
      "(34848, 445)\n",
      "(34848,)\n",
      "----- test\n",
      "(43560, 445)\n"
     ]
    }
   ],
   "source": [
    "print('----- train:')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('----- train_1')\n",
    "print(X_train_1.shape)\n",
    "print(y_train_1.shape)\n",
    "print('----- validation')\n",
    "print(X_validation.shape)\n",
    "print(y_validation.shape)\n",
    "print('----- test')\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on X_train_1 and y_train_1\n",
    "(we do this to evaluate the MLE with a validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressor loaded\n",
      "Iteration 1, loss = 2988.15995891\n",
      "Iteration 2, loss = 45.20411263\n",
      "Iteration 3, loss = 67.87601503\n",
      "Iteration 4, loss = 6469.01810715\n",
      "Iteration 5, loss = 170.65959234\n",
      "Iteration 6, loss = 37.07347298\n",
      "Iteration 7, loss = 37.65246037\n",
      "Iteration 8, loss = 108.45396415\n",
      "Iteration 9, loss = 95.75932910\n",
      "Iteration 10, loss = 1615.39035138\n",
      "Iteration 11, loss = 38.76132556\n",
      "Iteration 12, loss = 87.64722311\n",
      "Iteration 13, loss = 318.28709917\n",
      "Iteration 14, loss = 104.23461710\n",
      "Iteration 15, loss = 2539.88834955\n",
      "Iteration 16, loss = 34.99672604\n",
      "Iteration 17, loss = 32.51426871\n",
      "Iteration 18, loss = 137.70516708\n",
      "Iteration 19, loss = 1365.15821747\n",
      "Iteration 20, loss = 32.24855098\n",
      "Iteration 21, loss = 57.08675135\n",
      "Iteration 22, loss = 34.62608285\n",
      "Iteration 23, loss = 318.11488584\n",
      "Iteration 24, loss = 65.70767475\n",
      "Iteration 25, loss = 322.46087473\n",
      "Iteration 26, loss = 45.10298960\n",
      "Iteration 27, loss = 76.62903692\n",
      "Iteration 28, loss = 365.03150806\n",
      "Iteration 29, loss = 49.71709662\n",
      "Iteration 30, loss = 70.04083708\n",
      "Iteration 31, loss = 90.01338962\n",
      "Training loss did not improve more than tol=0.000001 for 10 consecutive epochs. Stopping.\n",
      "data fitted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#reg = Lasso(alpha=0.001)\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.00001, verbose = 1, max_iter=400, tol = 1*pow(10, -6))#use pytorch implementation instead (way faster)\n",
    "\n",
    "print(\"regressor loaded\")\n",
    "reg.fit(X_train_1, y_train_1)\n",
    "print('data fitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(y_pred_1, y_validation):\n",
    "    mse = (np.square(y_pred_1 - y_validation)).mean(axis=0)\n",
    "    print(y_pred_1[10:20])\n",
    "    print(y_validation[10:20])\n",
    "    print('MSE =',  mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data predicted\n",
      "[ 5.77212163  9.97485421  7.99284417  3.03551178 30.19739164  8.01789249\n",
      " 10.5685375   4.1815387   2.03831815  7.27398139]\n",
      "[10.  7.  9.  2. 33. 15.  6.  3.  1.  1.]\n",
      "MSE = 68.18358862074741\n"
     ]
    }
   ],
   "source": [
    "y_pred_1 = reg.predict(X_validation)\n",
    "print('data predicted')\n",
    "\n",
    "compute_mse(y_pred_1, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to to: cast the final values as integers then floats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on whole X_train\n",
    "(used for submission for better accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174241, 460)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regressor loaded\n",
      "Iteration 1, loss = 611.76928075\n",
      "Iteration 2, loss = 2015.26490950\n",
      "Iteration 3, loss = 50.89147264\n",
      "Iteration 4, loss = 92.80292838\n",
      "Iteration 5, loss = 181.17751738\n",
      "Iteration 6, loss = 633.24821262\n",
      "Iteration 7, loss = 507.24651179\n",
      "Iteration 8, loss = 217.45587512\n",
      "Iteration 9, loss = 153.50621455\n",
      "Iteration 10, loss = 272.17641987\n",
      "Iteration 11, loss = 381.90151610\n",
      "Iteration 12, loss = 62.85169288\n",
      "Iteration 13, loss = 3950.69218129\n",
      "Iteration 14, loss = 34.09516691\n",
      "Iteration 15, loss = 34.66467383\n",
      "Iteration 16, loss = 35.62793855\n",
      "Iteration 17, loss = 47.26593986\n",
      "Iteration 18, loss = 600.98670094\n",
      "Iteration 19, loss = 32.58747021\n",
      "Iteration 20, loss = 101.62147990\n",
      "Iteration 21, loss = 157.64609986\n",
      "Iteration 22, loss = 49.02982186\n",
      "Iteration 23, loss = 82.06309304\n",
      "Iteration 24, loss = 100.06606007\n",
      "Iteration 25, loss = 119.41570764\n",
      "Iteration 26, loss = 85.31511827\n",
      "Iteration 27, loss = 67.37877183\n",
      "Iteration 28, loss = 45.60185849\n",
      "Iteration 29, loss = 103.86330153\n",
      "Iteration 30, loss = 90.24019112\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "data fitted\n",
      "data predicted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#reg = Lasso(alpha=0.01)\n",
    "#might want to change batch size\n",
    "#might want to have several hidden layers\n",
    "reg = MLPRegressor(hidden_layer_sizes=(100, ), activation='relu', solver='adam', alpha=0.0001, max_iter=400, verbose=1)#use pytorch implementation instead (way faster)\n",
    "\n",
    "print(\"regressor loaded\")\n",
    "reg.fit(X_train, y_train)\n",
    "print('data fitted')\n",
    "y_pred = reg.predict(X_test)\n",
    "print('data predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data written\n"
     ]
    }
   ],
   "source": [
    "# write the predictions to file\n",
    "df_test['hindex'] = pd.Series(np.round_(y_pred, decimals=3))\n",
    "\n",
    "df_test.loc[:,[\"author\",\"hindex\"]].to_csv('submission.csv', index=False)\n",
    "print('data written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE AN MLP FROM PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on X_train_1 and y_train_1 using pytorch MLP\n",
    "(we do this to evaluate the MLE without needing to submit on kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  '''\n",
    "  Prepare the Boston dataset for regression\n",
    "  '''\n",
    "\n",
    "  def __init__(self, X, y, scale_data=True):\n",
    "    if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "      # Apply scaling if necessary\n",
    "      if scale_data:\n",
    "          X = StandardScaler().fit_transform(X)\n",
    "      self.X = torch.from_numpy(X)\n",
    "      self.y = torch.from_numpy(y)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.X)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "      return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron for regression.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      \n",
    "      nn.Linear(X_train_1.shape[1], 100),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(100, 60),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(60, 32),\n",
    "      nn.Dropout(0.5),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(32, 1),\n",
    "      nn.Dropout(0.8)\n",
    "      #nn.ReLU(),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''\n",
    "      Forward pass\n",
    "    '''\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might want to change the baseline\n",
    "\n",
    "# Prepare dataset\n",
    "# dataset = Dataset(X_train, y_train)\n",
    "# trainloader = torch.utils.data.DataLoader(dataset, batch_size=20, shuffle=True, num_workers=0)\n",
    "\n",
    "#training (with validation)\n",
    "dataset_train_1 = Dataset(X_train_1, y_train_1)\n",
    "trainloader = torch.utils.data.DataLoader(dataset_train_1, batch_size=600, shuffle=True, num_workers=0)\n",
    "\n",
    "#validation\n",
    "dataset_valid = Dataset(X_validation, y_validation)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=600, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize the MLP\n",
    "mlp = MLP().to(device)\n",
    "# Define the loss function and optimizer\n",
    "#loss_function = nn.L1Loss()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3, weight_decay=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=332, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=60, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=60, out_features=32, bias=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (8): Dropout(p=0.8, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINING\n",
    "\n",
    "def train_model(model, optizmizer, loss_function):\n",
    "    iter = 0\n",
    "    num_epochs = 100\n",
    "    history_train_acc, history_val_acc, history_train_loss, history_val_loss = [], [], [], []\n",
    "    #best_accuracy = 0\n",
    "\n",
    "    # Run the training loop\n",
    "    for epoch in range(num_epochs): \n",
    "      \n",
    "      # Print epoch\n",
    "      print(f'Starting epoch {epoch+1}')\n",
    "      \n",
    "      # Set current loss value\n",
    "      current_loss = 0.0\n",
    "      \n",
    "      # Iterate over the DataLoader for training data\n",
    "      for i, data in enumerate(trainloader):\n",
    "        best_val_loss = 10**10000\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Perform forward pass\n",
    "        #outputs = mlp(inputs)\n",
    "        #print('inputs: ', inputs.shape)\n",
    "       # print('model.layers', model.layers)\n",
    "        outputs = model(inputs)\n",
    "        #print('passed forward pass')\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "              # Get training statistics\n",
    "              train_loss = loss.data.item()\n",
    "\n",
    "              # Testing mode\n",
    "              model.eval()\n",
    "              # Calculate Accuracy         \n",
    "              correct = 0\n",
    "              total = 0\n",
    "              # Iterate through test dataset\n",
    "              for inputs, targets in valid_loader:\n",
    "                  # Load samples\n",
    "                  #samples = samples.view(-1, max_len).to(device)\n",
    "                  #labels = labels.view(-1).to(device)\n",
    "\n",
    "                  #inputs, targets = data\n",
    "                  inputs, targets = inputs.float().to(device), targets.float().to(device)\n",
    "                  targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "                  # Forward pass only to get logits/output\n",
    "                  outputs = model(inputs)\n",
    "\n",
    "                  # Val loss\n",
    "                  #val_loss = criterion(outputs.view(-1, 1), la.bels.view(-1, 1))\n",
    "                  val_loss = loss_function(outputs, targets)\n",
    "        # Print Loss\n",
    "              print('Iter: {} | Train Loss: {} | Val Loss: {} '.format(iter, train_loss, val_loss.item()))\n",
    "              # Append to history\n",
    "              history_val_loss.append(val_loss.data.item())\n",
    "              #history_val_acc.append(round(accuracy, 2))\n",
    "              history_train_loss.append(train_loss)\n",
    "\n",
    "              #to do: save the best model:\n",
    "              #we take the model with lowest \n",
    "              # Save model when accuracy beats best accuracy (TO DO !!!!)\n",
    "              if val_loss.data.item() < best_val_loss:\n",
    "                   best_val_loss = val_loss.data.item()\n",
    "              #     # We can load this best model on the validation set later\n",
    "                   torch.save(model.state_dict(), 'best_model.pth')\n",
    "    return (history_train_acc, history_val_acc, history_train_loss, history_val_loss)\n",
    "\n",
    "\n",
    "    #     # Print statistics\n",
    "    #     current_loss += loss.item()\n",
    "    #     if i % 1000 == 0:\n",
    "    #         print('Loss after mini-batch %5d: %.3f' %\n",
    "    #               (i + 1, current_loss / 500))\n",
    "    #         current_loss = 0.0\n",
    "\n",
    "    # # Process is complete.\n",
    "    # print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to update\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_losses(history_train_loss, history_val_loss):\n",
    "    # Set plotting style\n",
    "    #plt.style.use(('dark_background', 'bmh'))\n",
    "    plt.style.use('bmh')\n",
    "    plt.rc('axes', facecolor='none')\n",
    "    plt.rc('figure', figsize=(16, 4))\n",
    "\n",
    "    # Plotting loss graph\n",
    "    plt.plot(history_train_loss, label='Train')\n",
    "    plt.plot(history_val_loss, label='Validation')\n",
    "    plt.title('Loss Graph')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Starting epoch 2\n",
      "Iter: 100 | Train Loss: 276.1827697753906 | Val Loss: 243.7613525390625 \n",
      "Starting epoch 3\n",
      "Starting epoch 4\n",
      "Iter: 200 | Train Loss: 108.77285766601562 | Val Loss: 73.60255432128906 \n",
      "Starting epoch 5\n",
      "Starting epoch 6\n",
      "Iter: 300 | Train Loss: 156.51376342773438 | Val Loss: 85.48135375976562 \n",
      "Starting epoch 7\n",
      "Iter: 400 | Train Loss: 118.30912017822266 | Val Loss: 71.32695770263672 \n",
      "Starting epoch 8\n",
      "Starting epoch 9\n",
      "Iter: 500 | Train Loss: 92.95774841308594 | Val Loss: 57.54938507080078 \n",
      "Starting epoch 10\n",
      "Starting epoch 11\n",
      "Iter: 600 | Train Loss: 91.7079849243164 | Val Loss: 50.902549743652344 \n",
      "Starting epoch 12\n",
      "Iter: 700 | Train Loss: 81.655029296875 | Val Loss: 68.87342071533203 \n",
      "Starting epoch 13\n",
      "Starting epoch 14\n",
      "Iter: 800 | Train Loss: 100.67245483398438 | Val Loss: 81.23560333251953 \n",
      "Starting epoch 15\n",
      "Starting epoch 16\n",
      "Iter: 900 | Train Loss: 79.39380645751953 | Val Loss: 78.11705017089844 \n",
      "Starting epoch 17\n",
      "Iter: 1000 | Train Loss: 69.82415771484375 | Val Loss: 64.01739501953125 \n",
      "Starting epoch 18\n",
      "Starting epoch 19\n",
      "Iter: 1100 | Train Loss: 123.53073120117188 | Val Loss: 70.85674285888672 \n",
      "Starting epoch 20\n",
      "Starting epoch 21\n",
      "Iter: 1200 | Train Loss: 105.92745208740234 | Val Loss: 56.8984375 \n",
      "Starting epoch 22\n",
      "Starting epoch 23\n",
      "Iter: 1300 | Train Loss: 65.84252166748047 | Val Loss: 77.76546478271484 \n",
      "Starting epoch 24\n",
      "Iter: 1400 | Train Loss: 62.828678131103516 | Val Loss: 100.53302764892578 \n",
      "Starting epoch 25\n",
      "Starting epoch 26\n",
      "Iter: 1500 | Train Loss: 84.3355484008789 | Val Loss: 88.80475616455078 \n",
      "Starting epoch 27\n",
      "Starting epoch 28\n",
      "Iter: 1600 | Train Loss: 70.11356353759766 | Val Loss: 47.193946838378906 \n",
      "Starting epoch 29\n",
      "Iter: 1700 | Train Loss: 56.9626579284668 | Val Loss: 77.88994598388672 \n",
      "Starting epoch 30\n",
      "Starting epoch 31\n",
      "Iter: 1800 | Train Loss: 59.533634185791016 | Val Loss: 80.76758575439453 \n",
      "Starting epoch 32\n",
      "Starting epoch 33\n",
      "Iter: 1900 | Train Loss: 59.95286560058594 | Val Loss: 67.16613006591797 \n",
      "Starting epoch 34\n",
      "Iter: 2000 | Train Loss: 62.14344024658203 | Val Loss: 55.22066116333008 \n",
      "Starting epoch 35\n",
      "Starting epoch 36\n",
      "Iter: 2100 | Train Loss: 67.98503112792969 | Val Loss: 64.731689453125 \n",
      "Starting epoch 37\n",
      "Starting epoch 38\n",
      "Iter: 2200 | Train Loss: 54.39995193481445 | Val Loss: 81.5360107421875 \n",
      "Starting epoch 39\n",
      "Iter: 2300 | Train Loss: 51.89222717285156 | Val Loss: 65.57508087158203 \n",
      "Starting epoch 40\n",
      "Starting epoch 41\n",
      "Iter: 2400 | Train Loss: 47.83712387084961 | Val Loss: 83.66230010986328 \n",
      "Starting epoch 42\n",
      "Starting epoch 43\n",
      "Iter: 2500 | Train Loss: 49.91392517089844 | Val Loss: 72.34004211425781 \n",
      "Starting epoch 44\n",
      "Starting epoch 45\n",
      "Iter: 2600 | Train Loss: 44.02354431152344 | Val Loss: 70.01973724365234 \n",
      "Starting epoch 46\n",
      "Iter: 2700 | Train Loss: 54.54526901245117 | Val Loss: 75.69237518310547 \n",
      "Starting epoch 47\n",
      "Starting epoch 48\n",
      "Iter: 2800 | Train Loss: 36.8711051940918 | Val Loss: 89.13795471191406 \n",
      "Starting epoch 49\n",
      "Starting epoch 50\n",
      "Iter: 2900 | Train Loss: 47.48832702636719 | Val Loss: 63.694664001464844 \n",
      "Starting epoch 51\n",
      "Iter: 3000 | Train Loss: 38.862518310546875 | Val Loss: 130.4407501220703 \n",
      "Starting epoch 52\n",
      "Starting epoch 53\n",
      "Iter: 3100 | Train Loss: 42.501426696777344 | Val Loss: 74.64707946777344 \n",
      "Starting epoch 54\n",
      "Starting epoch 55\n",
      "Iter: 3200 | Train Loss: 34.53932189941406 | Val Loss: 159.79742431640625 \n",
      "Starting epoch 56\n",
      "Iter: 3300 | Train Loss: 31.893972396850586 | Val Loss: 66.6721420288086 \n",
      "Starting epoch 57\n",
      "Starting epoch 58\n",
      "Iter: 3400 | Train Loss: 33.22553253173828 | Val Loss: 82.4002685546875 \n",
      "Starting epoch 59\n",
      "Starting epoch 60\n",
      "Iter: 3500 | Train Loss: 30.712779998779297 | Val Loss: 91.29138946533203 \n",
      "Starting epoch 61\n",
      "Starting epoch 62\n",
      "Iter: 3600 | Train Loss: 29.795251846313477 | Val Loss: 86.63910675048828 \n",
      "Starting epoch 63\n",
      "Iter: 3700 | Train Loss: 27.70192527770996 | Val Loss: 94.76228332519531 \n",
      "Starting epoch 64\n",
      "Starting epoch 65\n",
      "Iter: 3800 | Train Loss: 26.988712310791016 | Val Loss: 102.77149200439453 \n",
      "Starting epoch 66\n",
      "Starting epoch 67\n",
      "Iter: 3900 | Train Loss: 36.91817092895508 | Val Loss: 69.84473419189453 \n",
      "Starting epoch 68\n",
      "Iter: 4000 | Train Loss: 24.26924705505371 | Val Loss: 71.2711410522461 \n",
      "Starting epoch 69\n",
      "Starting epoch 70\n",
      "Iter: 4100 | Train Loss: 24.01216697692871 | Val Loss: 72.94952392578125 \n",
      "Starting epoch 71\n",
      "Starting epoch 72\n",
      "Iter: 4200 | Train Loss: 23.969472885131836 | Val Loss: 75.38743591308594 \n",
      "Starting epoch 73\n",
      "Iter: 4300 | Train Loss: 22.972919464111328 | Val Loss: 95.29173278808594 \n",
      "Starting epoch 74\n",
      "Starting epoch 75\n",
      "Iter: 4400 | Train Loss: 24.518871307373047 | Val Loss: 96.11982727050781 \n",
      "Starting epoch 76\n",
      "Starting epoch 77\n",
      "Iter: 4500 | Train Loss: 23.914936065673828 | Val Loss: 94.36772918701172 \n",
      "Starting epoch 78\n",
      "Iter: 4600 | Train Loss: 20.594329833984375 | Val Loss: 126.9915771484375 \n",
      "Starting epoch 79\n",
      "Starting epoch 80\n",
      "Iter: 4700 | Train Loss: 23.89854621887207 | Val Loss: 84.89131927490234 \n",
      "Starting epoch 81\n",
      "Starting epoch 82\n",
      "Iter: 4800 | Train Loss: 18.760669708251953 | Val Loss: 71.71788787841797 \n",
      "Starting epoch 83\n",
      "Starting epoch 84\n",
      "Iter: 4900 | Train Loss: 21.72224998474121 | Val Loss: 161.22718811035156 \n",
      "Starting epoch 85\n",
      "Iter: 5000 | Train Loss: 22.560230255126953 | Val Loss: 87.2805404663086 \n",
      "Starting epoch 86\n",
      "Starting epoch 87\n",
      "Iter: 5100 | Train Loss: 21.829160690307617 | Val Loss: 82.22149658203125 \n",
      "Starting epoch 88\n",
      "Starting epoch 89\n",
      "Iter: 5200 | Train Loss: 20.78223991394043 | Val Loss: 79.90901947021484 \n",
      "Starting epoch 90\n",
      "Iter: 5300 | Train Loss: 22.455257415771484 | Val Loss: 107.53070068359375 \n",
      "Starting epoch 91\n",
      "Starting epoch 92\n",
      "Iter: 5400 | Train Loss: 16.222187042236328 | Val Loss: 152.6396484375 \n",
      "Starting epoch 93\n",
      "Starting epoch 94\n",
      "Iter: 5500 | Train Loss: 18.56817054748535 | Val Loss: 83.0758285522461 \n",
      "Starting epoch 95\n",
      "Iter: 5600 | Train Loss: 19.1528377532959 | Val Loss: 136.68734741210938 \n",
      "Starting epoch 96\n",
      "Starting epoch 97\n",
      "Iter: 5700 | Train Loss: 16.426145553588867 | Val Loss: 67.68726348876953 \n",
      "Starting epoch 98\n",
      "Starting epoch 99\n",
      "Iter: 5800 | Train Loss: 16.170684814453125 | Val Loss: 113.85283660888672 \n",
      "Starting epoch 100\n",
      "Iter: 5900 | Train Loss: 29.298877716064453 | Val Loss: 80.42870330810547 \n"
     ]
    }
   ],
   "source": [
    "(train_acc, val_acc, train_loss, val_loss) = train_model(mlp, optimizer, loss_function)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_losses(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = mlp\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.731997 171.36153   22.056097 ...  14.183601  12.009199  80.48586 ]\n",
      "[ 3. 14.  2. ...  1.  1.  1.]\n",
      "MSE = 6744.982241461019\n"
     ]
    }
   ],
   "source": [
    "#y_pred_train = mlp(torch.from_numpy(X_validation).float()).detach().numpy().T[0]\n",
    "\n",
    "best_model.cpu()\n",
    "mlp.cpu()\n",
    "y_pred_1 = best_model(torch.from_numpy(X_validation).float()).detach().numpy().T[0]\n",
    "print(y_pred_1)\n",
    "print(y_validation)\n",
    "compute_mse(y_pred_1, y_validation)\n",
    "#wtf ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO DO:\n",
    "\n",
    "#- split X_train, y_train into train and test, so we can evaluate the MSE\n",
    "\n",
    "# idea of features to add: (no learning)\n",
    "# - number of papers\n",
    "# - average of  number of papers of an author's co-author (will need the graph for this)\n",
    "\n",
    "# add graph features: (no learning)\n",
    "# see -> https://arxiv.org/ftp/arxiv/papers/1911/1911.08795.pdf\n",
    "\n",
    "#run and save node embeddings with different methods (Node2Vec, Deepwalk..) using karateclub libary \n",
    "#try to play with the paramters\n",
    "#record execution times\n",
    "\n",
    "#- look for new features/methods from texts. \n",
    "#- different ways of combining word embeddings ?\n",
    "#- train word embeddings on our dataset ?\n",
    "\n",
    "# - do a pipeline and test every possible combination of features\n",
    "# - (as done there https://github.com/vanessachahwan/ALTEGRAD-Challenge/blob/main/Report-BMV.pdf section 6)\n",
    "\n",
    "# - compare different regression models\n",
    "# - fine tune parameters for regression model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "345a0f5943a8075ed7616e2c3d9d78f5a99e0a39cacecea04843f429e3a92ccf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('test_karate': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
